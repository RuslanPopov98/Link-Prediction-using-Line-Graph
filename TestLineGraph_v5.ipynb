{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2085da5-e0d3-4179-868b-5c4244457275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import itertools\n",
    "\n",
    "import dgl.data\n",
    "import dgl.function as fn\n",
    "import dgl.nn.pytorch as dglnn\n",
    "from dgl.nn import GraphConv\n",
    "from dgl.nn import SumPooling\n",
    "from dgl.nn import DenseGraphConv\n",
    "from dgl.nn import SAGEConv\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "926081bd-ee99-4d16-a192-0b91f9bd8e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "    \n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            return g.edata['score'][:, 0]\n",
    "    \n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']\n",
    "        \n",
    "class FC(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats*2, h_feats*2)\n",
    "        self.W2 = nn.Linear(h_feats*2, h_feats)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']\n",
    "        \n",
    "def positive_sample(graph, test_size=0.1):\n",
    "    u, v = graph.edges()\n",
    "    eids = np.random.permutation(np.arange(graph.number_of_edges())) #random index edges\n",
    "    test_size_idx = int(len(eids) * test_size) #size positive sample by index\n",
    "\n",
    "    test_pos_u, test_pos_v = u[eids[:test_size_idx]], v[eids[:test_size_idx]]\n",
    "    train_pos_u, train_pos_v = u[eids[test_size_idx:]], v[eids[test_size_idx:]] \n",
    "    \n",
    "    train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=graph.number_of_nodes())\n",
    "    test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=graph.number_of_nodes())\n",
    "    \n",
    "    return train_pos_g, test_pos_g, eids\n",
    "\n",
    "\n",
    "def negative_sample(graph, method='kneighbors', size=None, test_size=None):   \n",
    "    new_g = graph.to_networkx()\n",
    "    adj = nx.to_numpy_array(new_g) #adjacency matrix\n",
    "    \n",
    "    if size == None:\n",
    "        size=g.number_of_nodes()\n",
    "    if test_size == None:\n",
    "        test_size=int(g.number_of_edges()*0.1)\n",
    "    \n",
    "    if method == 'dgl_example':\n",
    "        adj_neg = 1 - adj - np.eye(graph.number_of_nodes())\n",
    "        neg_u, neg_v = np.where(adj_neg != 0)\n",
    "        neg_eids = np.random.choice(len(neg_u), graph.number_of_edges() // 2) #negative sample random index\n",
    "        \n",
    "        test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
    "        train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]\n",
    "    \n",
    "    else:\n",
    "        negs_u = []\n",
    "        negs_v = []\n",
    "        negs = []\n",
    "        nnn = NearestNeighbors(n_neighbors=500, metric='cosine')\n",
    "        nnn.fit(adj)\n",
    "        res = nnn.kneighbors(return_distance=False) #top-5 nearest neightbord\n",
    "\n",
    "        for idx, i in enumerate(res):\n",
    "            for j in i:\n",
    "                if not new_g.has_edge(idx, j):\n",
    "                    negs.append([idx, j])\n",
    "\n",
    "        negs = np.array(negs)\n",
    "\n",
    "        for k in range(size):\n",
    "            temp = negs[np.random.permutation(negs.shape[0])[:graph.number_of_edges()]][0]\n",
    "            negs_u.append(temp[0])\n",
    "            negs_v.append(temp[1])\n",
    "            \n",
    "        test_neg_u, test_neg_v = negs_u[:test_size], negs_v[:test_size]\n",
    "        train_neg_u, train_neg_v = negs_u[test_size:], negs_v[test_size:]\n",
    "    \n",
    "    train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=graph.number_of_nodes())\n",
    "    test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=graph.number_of_nodes())\n",
    "            \n",
    "    return train_neg_g, test_neg_g\n",
    "\n",
    "\n",
    "def alternate_list(a,b):\n",
    "    c = list()\n",
    "    for x in range(len(a)):\n",
    "        c.extend([a[x], b[x]])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0676d416-3213-414b-9374-85b81d39e86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 1475\n",
      "300 2950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=300, num_edges=2950,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create random graph\n",
    "# spmat = sp.rand(1000, 1000, density=0.003) # 5% nonzero entries\n",
    "# g = dgl.from_scipy(spmat)\n",
    "nx_g = nx.barabasi_albert_graph(300,5)#300, 5)\n",
    "print(nx_g.number_of_nodes(), nx_g.number_of_edges())\n",
    "g = dgl.from_networkx(nx_g, )\n",
    "G = g.to_networkx()\n",
    "print(G.number_of_nodes(), G.number_of_edges())\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae313913-133f-4bd5-a790-72893ac0fa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "2708\n",
      "10556\n"
     ]
    }
   ],
   "source": [
    "dataset = dgl.data.CoraGraphDataset()\n",
    "g = dataset[0]\n",
    "\n",
    "# g = dgl.remove_edges(g, eids[:1000], ) #subgraph\n",
    "# g = dgl.remove_nodes(g, range(2000))\n",
    "# print(g)\n",
    "\n",
    "G = g.to_networkx()\n",
    "\n",
    "print(len(list(G.nodes())))\n",
    "print(len(list(G.edges())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e222c3-331e-482c-8f55-5537b992e44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_pos_shape = [2708, 9501] ; test_pos_shape = [2708, 1055]\n",
      "train_neg_shape = [2708, 4223] ; test_neg_shape = [2708, 1055]\n"
     ]
    }
   ],
   "source": [
    "# train-test and positive-negative sampling\n",
    "train_pos_g, test_pos_g, eids = positive_sample(g)\n",
    "train_neg_g, test_neg_g = negative_sample(g, 'dgl_example')\n",
    "###########\n",
    "print('train_pos_shape =', [len(train_pos_g.nodes()), len(train_pos_g.edges()[0])], '; test_pos_shape =', [len(test_pos_g.nodes()), len(test_pos_g.edges()[0])])\n",
    "print('train_neg_shape =', [len(train_neg_g.nodes()), len(train_neg_g.edges()[0])], '; test_neg_shape =', [len(test_neg_g.nodes()), len(test_neg_g.edges()[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85685280-7711-4708-be47-68ed142dbcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2708\n",
      "9501\n"
     ]
    }
   ],
   "source": [
    "G = train_pos_g.to_networkx()\n",
    "print(len(list(G.nodes())))\n",
    "print(len(list(G.edges())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "324cab81-40c3-44d7-97b6-eab141e96b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node2vec parameters \n",
    "dimensions=10\n",
    "walk_length=10\n",
    "window=10\n",
    "min_count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75282fae-dbf9-465b-9663-20b59dd07664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6428e3c81a4e84923bcb8f0ee13aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/2708 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:00<00:00, 10.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# create node features\n",
    "node2vec = Node2Vec(G, dimensions=dimensions, walk_length=walk_length)#, workers=6)\n",
    "model_n2v = node2vec.fit(window=window, min_count=min_count)\n",
    "embeddings = np.array([model_n2v.wv[x] for x in list(G.nodes())])\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "g.ndata['feat'] = embeddings                       # f_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "078ea938-0d43-47c9-a6fe-3f50d8a72fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(embeddings[:5] - g.ndata['feat'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee8ea2f4-be24-4f1f-860a-3bccdd3a5d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_size = 1055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2708, num_edges=9501,\n",
       "      ndata_schemes={'feat': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'train_mask': Scheme(shape=(), dtype=torch.bool)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size=int(g.number_of_edges()*0.1)\n",
    "print('test_size =', test_size)\n",
    "train_g = dgl.remove_edges(g, eids[:test_size])\n",
    "train_g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a895d3e2-bd7e-406e-a819-65641ac3f26f",
   "metadata": {},
   "source": [
    "### line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a8098c4-193e-4e47-913d-25d808254d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diffrent number of G.nodes LnxG.nodes! Used DiGraph.\n"
     ]
    }
   ],
   "source": [
    "# create line graph \n",
    "temp_G = nx.Graph()\n",
    "temp_G.add_edges_from(list(G.edges()))\n",
    "LnxG = nx.line_graph(temp_G)\n",
    "\n",
    "if len(list(LnxG.nodes())) != len(list(G.edges())):\n",
    "    print('diffrent number of G.nodes LnxG.nodes! Used DiGraph.')\n",
    "    temp_G = nx.DiGraph()\n",
    "    temp_G.add_edges_from(list(G.edges()))\n",
    "    LnxG = nx.line_graph(temp_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c64ac6a4-9ab0-480f-a6aa-17e361fd767b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9501 [(0, 633), (0, 1862), (0, 2582), (1, 2), (1, 652), (1, 654), (2, 1), (2, 1454), (2, 1666), (2, 1986)]\n"
     ]
    }
   ],
   "source": [
    "print(len(list(G.edges())), sorted(list(G.edges()),reverse=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "960e5b33-0d0e-497b-ba52-3fda882b4c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9501 [(0, 633), (0, 1862), (0, 2582), (1, 2), (1, 652), (1, 654), (2, 1), (2, 1454), (2, 1666), (2, 1986)]\n",
      "93138 [((0, 2582), (2582, 0)), ((0, 2582), (2582, 1166)), ((0, 2582), (2582, 1862)), ((2582, 0), (0, 2582)), ((2582, 0), (0, 633)), ((2582, 0), (0, 1862)), ((2582, 1166), (1166, 2582)), ((2582, 1166), (1166, 1986)), ((2582, 1862), (1862, 926)), ((2582, 1862), (1862, 1701))]\n"
     ]
    }
   ],
   "source": [
    "print(len(list(LnxG.nodes())), sorted(list(LnxG.nodes()),reverse=False)[:10])\n",
    "print(len(list(LnxG.edges())), list(LnxG.edges())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43154966-2fb3-4e14-9292-3667905d07b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9501 93138\n"
     ]
    }
   ],
   "source": [
    "# lg - line graph on DGL; LG - line grpah on nx\n",
    "# ф-ция, которая переназывает вершины и ребра дуального графа\n",
    "# если вершина была  (0, 633), то может стать вершиной 5, например\n",
    "def create_dgl_nx_dual_graph(line_nx_graph):\n",
    "    nodes = sorted(list(line_nx_graph.nodes()),reverse=False)\n",
    "    edges = list(line_nx_graph.edges())\n",
    "    nodes_dict = {}\n",
    "    new_u, new_v = [], []\n",
    "    \n",
    "    for idx, val in enumerate(nodes):\n",
    "        nodes_dict[val] = idx\n",
    "    \n",
    "    print(len(nodes_dict), len(edges))\n",
    "    for edge in edges:\n",
    "        new_u.append(nodes_dict[edge[0]])\n",
    "        new_v.append(nodes_dict[edge[1]])\n",
    "    \n",
    "    u = torch.tensor(new_u)\n",
    "    v = torch.tensor(new_v)\n",
    "    g = dgl.graph((u, v))\n",
    "    G = g.to_networkx()\n",
    "    return g, G\n",
    "    \n",
    "    \n",
    "lg, LG = create_dgl_nx_dual_graph(LnxG)\n",
    "dual_edges_dict = {edge: num for num, edge in enumerate(list(LG.edges()))}\n",
    "dual_nodes_dict = {node: num for num, node in enumerate(sorted(list(LnxG.nodes()),reverse=False))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bde5cb2-c9fe-4130-a2c2-e934d6d7c043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9501 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "93138\n",
      "[(0, 2328), (0, 2329), (0, 2330), (1, 6834), (1, 6835), (1, 6833), (1, 6836), (2, 9280), (2, 9281), (2, 9282)]\n"
     ]
    }
   ],
   "source": [
    "#print(len(dual_nodes_dict))\n",
    "#print(len(dual_edges_dict))\n",
    "print(len(list(LG.nodes)), list(LG.nodes)[:10])\n",
    "print(len(list(LG.edges)))\n",
    "print(list(LG.edges())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20169f77-718c-499f-8092-e8e430156cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9501 [tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9)]\n",
      "93138\n",
      "tensor([   2,    2,    2, 9280, 9280, 9280, 9281, 9281, 9282, 9282]) tensor([   2,    2,    2, 9280, 9280, 9280, 9281, 9281, 9282, 9282])\n"
     ]
    }
   ],
   "source": [
    "print(len(list(lg.nodes())), list(lg.nodes())[:10])\n",
    "print(len(list(lg.edges())[0]))\n",
    "print(list(lg.edges())[0][:10], list(lg.edges())[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81342138-b455-487e-8ca6-3ec570929918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1814c16adaae4a8d8e72fe0afb25b100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/9501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:04<00:00,  2.26it/s]\n",
      "/var/folders/cm/gfrlqbxx32b2v0hgshlc8mk00000gn/T/ipykernel_28511/3184879234.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/distiller/project/pytorch/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  embeddings_dual = torch.tensor(embeddings_dual)\n"
     ]
    }
   ],
   "source": [
    "# create node features to line graph\n",
    "\n",
    "# m = nn.AvgPool1d(2, stride=2)\n",
    "node2vec = Node2Vec(LnxG, dimensions=dimensions, walk_length=walk_length)\n",
    "model_n2v_dual = node2vec.fit(window=window, min_count=min_count)\n",
    "#embeddings_dual = [[alternate_list(model_n2v_dual.wv[x][0],model_n2v_dual.wv[x][1]) for x in list(LnxG.nodes)]]\n",
    "embeddings_dual = [model_n2v_dual.wv[x] for x in list(LG.nodes)]\n",
    "#embeddings_dual = m(torch.tensor(embeddings_dual))[0]\n",
    "#embeddings_dual = (torch.tensor(embeddings_dual))[0]\n",
    "embeddings_dual = torch.tensor(embeddings_dual)\n",
    "lg.ndata['feat'] = embeddings_dual                #f_uv^*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa9ec8df-864f-4c47-ac6d-770965e4a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(embeddings_dual[:5] - lg.ndata['feat'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a032fd6c-90af-418d-8de6-0fb89b65ad3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=9501, num_edges=93138,\n",
      "      ndata_schemes={'feat': Scheme(shape=(10,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "train_dual_g = lg #dgl.remove_edges(dual_g, eids[:int(len(dual_eids) * 0.1)]) #subgraph\n",
    "print(train_dual_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b474b427-8b32-439b-9d49-90e96f358a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(train_g.ndata['feat'].shape[1], dimensions)\n",
    "FC_net = FC(dimensions)\n",
    "###############################################################\n",
    "model_dual = GraphSAGE(train_dual_g.ndata['feat'].shape[1], dimensions)\n",
    "FC_net_dual = FC(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "866493b7-286e-46b3-98b8-cc9bb7e4c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def g_u_star(G, LnxG, pos_score_dual):\n",
    "#     node_features = np.zeros((G.number_of_nodes(), dimensions))\n",
    "#     counts = np.zeros((G.number_of_nodes(), 1))\n",
    "\n",
    "#     for node in list(G.nodes()):\n",
    "#         for i, edge in enumerate(list(LnxG.edges())):\n",
    "#             if (node in edge[0])or(node in edge[1]):\n",
    "#                 n1, n2 = dual_nodes_dict[edge[0]], dual_nodes_dict[edge[1]]\n",
    "#                 #print(edge, n1, n2)\n",
    "#                 try:\n",
    "#                     num_embd_edge_G_star = dual_edges_dict[(n1, n2)]\n",
    "#                     node_features[node] += pos_score_dual[num_embd_edge_G_star].detach().numpy()\n",
    "#                     counts[node] += 1\n",
    "#                     #print(pos_score_dual[num_embd_edge_G_star])\n",
    "#                 except: print('NUN', edge)\n",
    "#         #print(counts)\n",
    "#         if counts[node] != 0:\n",
    "#             node_features[node]/=counts[node]\n",
    "        \n",
    "#     return torch.from_numpy(node_features)\n",
    "\n",
    "\n",
    "def sum_by_label(samples, labels, max_label):\n",
    "    weight = torch.zeros(max_label, samples.shape[0]).to(samples.device) # L, N\n",
    "    weight[labels, torch.arange(samples.shape[0])] = 1\n",
    "    #print(weight)\n",
    "    label_count = weight.sum(dim=1)\n",
    "    #print(label_count)\n",
    "    #print(samples)\n",
    "    #print(torch.mm(weight, samples))\n",
    "    return torch.mm(weight, samples), label_count # L, F\n",
    "\n",
    "# lg.ndata[\"node_from\"], lg.ndata[\"node_to\"] = g.edges()\n",
    "# line_g.edata[\"h\"] = torch.rand((line_g.num_edges(), 3))\n",
    "\n",
    "def g_u_star(embedd):\n",
    "    lg.ndata[\"node_from\"], lg.ndata[\"node_to\"] = train_g.edges()\n",
    "    src, dst = lg.edges()\n",
    "    label_from_from = lg.ndata[\"node_from\"][src]\n",
    "    label_to_from = lg.ndata[\"node_to\"][src]\n",
    "    label_from_to = lg.ndata[\"node_from\"][dst]\n",
    "    label_to_to = lg.ndata[\"node_to\"][dst]\n",
    "    \n",
    "    label_from_from_sum, label_count_1 = sum_by_label(embedd, label_from_from, train_g.num_nodes())\n",
    "    label_to_from_sum, label_count_2 = sum_by_label(embedd, label_to_from, train_g.num_nodes())\n",
    "    label_from_to_sum, label_count_3 = sum_by_label(embedd, label_from_to, train_g.num_nodes())\n",
    "    label_to_to_sum, label_count_4 = sum_by_label(embedd, label_to_to, train_g.num_nodes())\n",
    "    \n",
    "    if torch.all(torch.eq(label_from_from_sum,label_to_from_sum)):\n",
    "        label_to_from_sum=0\n",
    "    elif torch.all(torch.eq(label_from_from_sum,label_from_to_sum)):\n",
    "        label_from_to_sum=0\n",
    "    elif torch.all(torch.eq(label_from_from_sum,label_to_to_sum)):\n",
    "        label_to_to_sum=0\n",
    "    elif torch.all(torch.eq(label_to_from_sum,label_from_to_sum)):\n",
    "        label_from_to_sum=0\n",
    "    elif torch.all(torch.eq(label_to_from_sum,label_to_to_sum)):\n",
    "        label_to_to_sum=0\n",
    "    else: label_to_to_sum=0\n",
    "    \n",
    "    label_count = label_count_1 + label_count_2 + label_count_3 + label_count_4\n",
    "    label_sum = (label_from_from_sum + label_to_from_sum + label_from_to_sum + label_to_to_sum)\n",
    "    for i in range(len(label_count)):\n",
    "        if label_count[i] != 0:\n",
    "            label_sum[i]/=label_count[i]\n",
    "    \n",
    "    return label_sum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4218b5a-f237-4850-8a3a-d8571f842f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#G.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7609b7fa-7cb4-4a75-8649-aaa2c400c4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1, 1, 1, 2, 3, 4, 5, 6, 7, 7, 7, 8, 9])\n",
      "tensor([1, 2, 7, 0, 3, 5, 6, 0, 1, 1, 1, 1, 0, 8, 9, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "lg.ndata[\"node_from\"], lg.ndata[\"node_to\"] = train_g.edges()\n",
    "print(lg.ndata[\"node_from\"])\n",
    "print(lg.ndata[\"node_to\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ce21711-2b5a-45a0-a90f-0532b1e3c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_for_train_SAGE(alpha, beta, z_u, g_u_star, g_uv, z_uv_star):\n",
    "    res1 = alpha*((z_u - g_u_star)**2).mean()\n",
    "    res2 = beta*((g_uv - z_uv_star)**2).mean()\n",
    "    return res1 + res2 \n",
    "    # return alfa*((z_u - g_u_star)**2).mean() + beta*((g_uv - z_uv_star)**2).mean()\n",
    "    #return alfa*F.binary_cross_entropy_with_logits(z_u, g_u_star)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6352b08-d618-46f3-8165-01b9873ddd17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "  0%|          | 1/200 [00:04<13:31,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 11.369186401367188, time_g_u_s: 2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [01:12<10:14,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 20, loss: 0.7243455052375793, time_g_u_s: 37 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [02:21<09:06,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 40, loss: 0.19426237046718597, time_g_u_s: 40 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 61/200 [03:32<07:58,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 60, loss: 0.08347255736589432, time_g_u_s: 40 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 81/200 [04:41<06:50,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 80, loss: 0.04538017511367798, time_g_u_s: 40 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 101/200 [05:51<05:42,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 100, loss: 0.028710264712572098, time_g_u_s: 40 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 121/200 [07:00<04:31,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 120, loss: 0.01971302181482315, time_g_u_s: 40 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 141/200 [08:10<03:23,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 140, loss: 0.014259664341807365, time_g_u_s: 40 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 161/200 [09:20<02:13,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 160, loss: 0.01072546187788248, time_g_u_s: 39 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 181/200 [10:28<01:04,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 180, loss: 0.008333282545208931, time_g_u_s: 40 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [11:34<00:00,  3.47s/it]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), FC_net.parameters()), lr=0.01)\n",
    "optimizer_d = torch.optim.Adam(itertools.chain(model_dual.parameters(), FC_net_dual.parameters()), lr=0.01)\n",
    "\n",
    "all_logits, diff = [], 0\n",
    "alpha, beta = 0.5, 1.\n",
    "\n",
    "for e in tqdm(range(200)):\n",
    "    h = model(train_g, embeddings)                              #z_u\n",
    "    h_dual = model_dual(train_dual_g, embeddings_dual)          #z_uv^*\n",
    "    \n",
    "    pos_score = FC_net(train_g, h)                              #g_uv\n",
    "    #neg_score = pred(train_neg_g, h)                           #g_uv -\n",
    "    pos_score_dual = FC_net_dual(train_dual_g, h_dual)          #g_u^*\n",
    "    #neg_score_dual = pred(train_neg_dual_g, h_dual)            #g_u^* -\n",
    "    start = time.time()\n",
    "    #g_u_s = g_u_star(G, LnxG, pos_score_dual)\n",
    "    g_u_s = g_u_star(pos_score_dual)\n",
    "    end = time.time()\n",
    "    diff += int(end - start)\n",
    "    loss = compute_loss_for_train_SAGE(alpha, beta, h, g_u_s, pos_score, h_dual)\n",
    "    \n",
    "    # print(h.shape)\n",
    "    # print(h_dual.shape)\n",
    "    # print(pos_score.shape)\n",
    "    # print(pos_score_dual.shape)\n",
    "    # print(g_u_s.shape)\n",
    "    # print(loss, F.mse_loss(h, g_u_s), F.mse_loss(pos_score, h_dual))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    optimizer_d.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer_d.step()\n",
    "\n",
    "    if e % 20 == 0:\n",
    "        print('In epoch {}, loss: {}, time_g_u_s: {} s'.format(e, loss, diff))\n",
    "        diff = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22b25356-f9af-4909-8cbb-f1bf0d008def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0067, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71a51fd-aa69-4c33-bdcf-be7ba22979ad",
   "metadata": {},
   "source": [
    "# LP Task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "313e3995-6245-4dc5-8895-c117bae728b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])    \n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "    #return ((scores - labels)**2).mean() \n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e87e2d9-ff74-47eb-96e5-e8c0bad94195",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lp = GraphSAGE(train_g.ndata['feat'].shape[1], 20)\n",
    "pred_lp = MLPPredictor(dimensions)\n",
    "#pred_lp = DotPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e7f1d914-2e9f-474c-a812-67785a784425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=2708, num_edges=9501,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n",
      "Graph(num_nodes=2708, num_edges=4223,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "print(train_pos_g)\n",
    "print(train_neg_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2d7b9ee6-510d-4247-907f-a86eb0808d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.5216617584228516\n",
      "In epoch 10, loss: 0.5215570330619812\n",
      "In epoch 20, loss: 0.5215683579444885\n",
      "In epoch 30, loss: 0.5212752819061279\n",
      "In epoch 40, loss: 0.521124541759491\n",
      "In epoch 50, loss: 0.5209746360778809\n",
      "In epoch 60, loss: 0.5208260416984558\n",
      "In epoch 70, loss: 0.5206786394119263\n",
      "In epoch 80, loss: 0.520526111125946\n",
      "In epoch 90, loss: 0.5203730463981628\n",
      "In epoch 100, loss: 0.5202264785766602\n",
      "In epoch 110, loss: 0.5200818181037903\n",
      "In epoch 120, loss: 0.5199338793754578\n",
      "In epoch 130, loss: 0.5197877883911133\n",
      "In epoch 140, loss: 0.5196406841278076\n",
      "In epoch 150, loss: 0.5194856524467468\n",
      "In epoch 160, loss: 0.5193227529525757\n",
      "In epoch 170, loss: 0.5191634893417358\n",
      "In epoch 180, loss: 0.5190067291259766\n",
      "In epoch 190, loss: 0.5188459753990173\n",
      "AUC 0.6613117405269424\n"
     ]
    }
   ],
   "source": [
    "optimizer_lp = torch.optim.Adam(pred_lp.parameters(), lr=0.01)\n",
    "\n",
    "all_logits = []\n",
    "for e in range(200):\n",
    "    model.eval()\n",
    "    h = h.detach()\n",
    "    #h_after_GCN = model(train_g, embeddings)  #train_g.ndata['feat'])\n",
    "    pos_score = pred_lp(train_pos_g, h)\n",
    "    neg_score = pred_lp(train_neg_g, h)\n",
    "    loss_lp = compute_loss(pos_score, neg_score)\n",
    "    \n",
    "    #print(loss_lp)\n",
    "    \n",
    "    optimizer_lp.zero_grad()\n",
    "    loss_lp.backward()\n",
    "    optimizer_lp.step()\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(e, loss_lp))\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "with torch.no_grad():\n",
    "    h = h.detach()\n",
    "    pos_score = pred_lp(test_pos_g, h)\n",
    "    neg_score = pred_lp(test_neg_g, h)\n",
    "    print('AUC', compute_auc(pos_score, neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f15a8ba9-27e6-4318-8f92-7e7bf1cf5235",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e43c614e-94de-4d1f-973b-15b885aa8ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha, beta = 0.5 , 1.0 -> AUC 0.6613117405269424\n"
     ]
    }
   ],
   "source": [
    "print('alpha, beta =', alpha, ',',beta, '-> AUC', compute_auc(pos_score, neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58984145-2c6b-4f85-afd6-953039659008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha, beta = 0.5, 1.0 -> AUC 0.55\n",
    "# alpha, beta = 0.25, 1.0 -> AUC 0.525\n",
    "# alpha, beta = 0.1, 1.0 -> AUC 0.5\n",
    "\n",
    "# alpha, beta = 0.9, 0.9 -> AUC 0.48\n",
    "# alpha, beta = 1.0, 0.5 -> AUC 0.48\n",
    "# alpha, beta = 1.0, 0.25 -> AUC 0.45\n",
    "\n",
    "# alpha, beta = 0.5, 0.9 -> AUC 0.54\n",
    "# alpha, beta = 0.5, 0.5 -> AUC 0.59\n",
    "# alpha, beta = 0.1, 0.5 -> AUC 0.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d25159d-49ff-4aee-974d-0c507ab3f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha, beta = 0.5, 1. -> AUC 0.7399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857339f9-2ad7-4106-bb0d-aeef4357f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph: num_nodes=1000, num_edges=3000\n",
    "# alpha, beta = 0.4, 1.0 -> AUC 0.50885\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
