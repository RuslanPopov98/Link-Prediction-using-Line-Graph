{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2085da5-e0d3-4179-868b-5c4244457275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import itertools\n",
    "\n",
    "import dgl.data\n",
    "import dgl.function as fn\n",
    "import dgl.nn.pytorch as dglnn\n",
    "from dgl.nn import GraphConv\n",
    "from dgl.nn import SumPooling\n",
    "from dgl.nn import DenseGraphConv\n",
    "from dgl.nn import SAGEConv\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "926081bd-ee99-4d16-a192-0b91f9bd8e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "    \n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            return g.edata['score'][:, 0]\n",
    "    \n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']\n",
    "        \n",
    "class FC(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats*2, h_feats*2)\n",
    "        self.W2 = nn.Linear(h_feats*2, h_feats)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']\n",
    "        \n",
    "def positive_sample(graph, test_size=0.1):\n",
    "    u, v = graph.edges()\n",
    "    eids = np.random.permutation(np.arange(graph.number_of_edges())) #random index edges\n",
    "    test_size_idx = int(len(eids) * test_size) #size positive sample by index\n",
    "\n",
    "    test_pos_u, test_pos_v = u[eids[:test_size_idx]], v[eids[:test_size_idx]]\n",
    "    train_pos_u, train_pos_v = u[eids[test_size_idx:]], v[eids[test_size_idx:]] \n",
    "    \n",
    "    train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=graph.number_of_nodes())\n",
    "    test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=graph.number_of_nodes())\n",
    "    \n",
    "    return train_pos_g, test_pos_g, eids\n",
    "\n",
    "\n",
    "def negative_sample(graph, method='kneighbors', size=None, test_size=None):   \n",
    "    new_g = graph.to_networkx()\n",
    "    adj = nx.to_numpy_array(new_g) #adjacency matrix\n",
    "    \n",
    "    if size == None:\n",
    "        size=g.number_of_nodes()\n",
    "    if test_size == None:\n",
    "        test_size=int(g.number_of_edges()*0.1)\n",
    "    \n",
    "    if method == 'dgl_example':\n",
    "        adj_neg = 1 - adj - np.eye(graph.number_of_nodes())\n",
    "        neg_u, neg_v = np.where(adj_neg != 0)\n",
    "        neg_eids = np.random.choice(len(neg_u), graph.number_of_edges() // 2) #negative sample random index\n",
    "        \n",
    "        test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
    "        train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]\n",
    "    \n",
    "    else:\n",
    "        negs_u = []\n",
    "        negs_v = []\n",
    "        negs = []\n",
    "        nnn = NearestNeighbors(n_neighbors=500, metric='cosine')\n",
    "        nnn.fit(adj)\n",
    "        res = nnn.kneighbors(return_distance=False) #top-5 nearest neightbord\n",
    "\n",
    "        for idx, i in enumerate(res):\n",
    "            for j in i:\n",
    "                if not new_g.has_edge(idx, j):\n",
    "                    negs.append([idx, j])\n",
    "\n",
    "        negs = np.array(negs)\n",
    "\n",
    "        for k in range(size):\n",
    "            temp = negs[np.random.permutation(negs.shape[0])[:graph.number_of_edges()]][0]\n",
    "            negs_u.append(temp[0])\n",
    "            negs_v.append(temp[1])\n",
    "            \n",
    "        test_neg_u, test_neg_v = negs_u[:test_size], negs_v[:test_size]\n",
    "        train_neg_u, train_neg_v = negs_u[test_size:], negs_v[test_size:]\n",
    "    \n",
    "    train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=graph.number_of_nodes())\n",
    "    test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=graph.number_of_nodes())\n",
    "            \n",
    "    return train_neg_g, test_neg_g\n",
    "\n",
    "\n",
    "def alternate_list(a,b):\n",
    "    c = list()\n",
    "    for x in range(len(a)):\n",
    "        c.extend([a[x], b[x]])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0676d416-3213-414b-9374-85b81d39e86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=100, num_edges=100,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create random graph\n",
    "spmat = sp.rand(100, 100, density=0.01) # 5% nonzero entries\n",
    "g = dgl.from_scipy(spmat)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae313913-133f-4bd5-a790-72893ac0fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dgl.data.CoraGraphDataset()\n",
    "# g = dataset[0]\n",
    "\n",
    "# g = dgl.remove_edges(g, eids[:1000], ) #subgraph\n",
    "# g = dgl.remove_nodes(g, range(2000))\n",
    "# print(g)\n",
    "\n",
    "# G = g.to_networkx()\n",
    "\n",
    "# print(len(list(G.nodes())))\n",
    "# print(len(list(G.edges())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9e222c3-331e-482c-8f55-5537b992e44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_pos_shape = [100, 90] ; test_pos_shape = [100, 10]\n",
      "train_neg_shape = [100, 40] ; test_neg_shape = [100, 10]\n"
     ]
    }
   ],
   "source": [
    "# train-test and positive-negative sampling\n",
    "train_pos_g, test_pos_g, eids = positive_sample(g)\n",
    "train_neg_g, test_neg_g = negative_sample(g, 'dgl_example')\n",
    "###########\n",
    "print('train_pos_shape =', [len(train_pos_g.nodes()), len(train_pos_g.edges()[0])], '; test_pos_shape =', [len(test_pos_g.nodes()), len(test_pos_g.edges()[0])])\n",
    "print('train_neg_shape =', [len(train_neg_g.nodes()), len(train_neg_g.edges()[0])], '; test_neg_shape =', [len(test_neg_g.nodes()), len(test_neg_g.edges()[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85685280-7711-4708-be47-68ed142dbcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "G = train_pos_g.to_networkx()\n",
    "print(len(list(G.nodes())))\n",
    "print(len(list(G.edges())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "324cab81-40c3-44d7-97b6-eab141e96b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node2vec parameters \n",
    "dimensions=10\n",
    "walk_length=10\n",
    "window=10\n",
    "min_count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75282fae-dbf9-465b-9663-20b59dd07664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4835beb2d75040028885e93faa3616db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:00<00:00, 1073.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# create node features\n",
    "node2vec = Node2Vec(G, dimensions=dimensions, walk_length=walk_length)#, workers=6)\n",
    "model_n2v = node2vec.fit(window=window, min_count=min_count)\n",
    "embeddings = np.array([model_n2v.wv[x] for x in list(G.nodes())])\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "g.ndata['feat'] = embeddings                       # f_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "078ea938-0d43-47c9-a6fe-3f50d8a72fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(embeddings[:5] - g.ndata['feat'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee8ea2f4-be24-4f1f-860a-3bccdd3a5d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_size = 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=100, num_edges=90,\n",
       "      ndata_schemes={'feat': Scheme(shape=(10,), dtype=torch.float32)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size=int(g.number_of_edges()*0.1)\n",
    "print('test_size =', test_size)\n",
    "train_g = dgl.remove_edges(g, eids[:test_size])\n",
    "train_g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a895d3e2-bd7e-406e-a819-65641ac3f26f",
   "metadata": {},
   "source": [
    "### line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a8098c4-193e-4e47-913d-25d808254d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diffrent number of G.nodes LnxG.nodes! Used DiGraph.\n"
     ]
    }
   ],
   "source": [
    "# create line graph \n",
    "temp_G = nx.Graph()\n",
    "temp_G.add_edges_from(list(G.edges()))\n",
    "LnxG = nx.line_graph(temp_G)\n",
    "\n",
    "if len(list(LnxG.nodes())) != len(list(G.edges())):\n",
    "    print('diffrent number of G.nodes LnxG.nodes! Used DiGraph.')\n",
    "    temp_G = nx.DiGraph()\n",
    "    temp_G.add_edges_from(list(G.edges()))\n",
    "    LnxG = nx.line_graph(temp_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c64ac6a4-9ab0-480f-a6aa-17e361fd767b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 [(0, 86), (1, 37), (1, 80), (2, 18), (2, 36), (5, 13), (6, 47), (8, 53), (8, 76), (10, 19)]\n"
     ]
    }
   ],
   "source": [
    "print(len(list(G.edges())), sorted(list(G.edges()),reverse=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "960e5b33-0d0e-497b-ba52-3fda882b4c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 [(0, 86), (1, 37), (1, 80), (2, 18), (2, 36), (5, 13), (6, 47), (8, 53), (8, 76), (10, 19)]\n",
      "81 [((0, 86), (86, 69)), ((86, 69), (69, 13)), ((69, 13), (13, 45)), ((2, 18), (18, 93)), ((5, 13), (13, 45)), ((13, 45), (45, 13)), ((45, 13), (13, 45)), ((8, 76), (76, 68)), ((8, 53), (53, 10)), ((8, 53), (53, 59))]\n"
     ]
    }
   ],
   "source": [
    "print(len(list(LnxG.nodes())), sorted(list(LnxG.nodes()),reverse=False)[:10])\n",
    "print(len(list(LnxG.edges())), list(LnxG.edges())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43154966-2fb3-4e14-9292-3667905d07b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 81\n"
     ]
    }
   ],
   "source": [
    "# lg - line graph on DGL; LG - line grpah on nx\n",
    "# ф-ция, которая переназывает вершины и ребра дуального графа\n",
    "# если вершина была  (0, 633), то может стать вершиной 5, например\n",
    "def create_dgl_nx_dual_graph(line_nx_graph):\n",
    "    nodes = sorted(list(line_nx_graph.nodes()),reverse=False)\n",
    "    edges = list(line_nx_graph.edges())\n",
    "    nodes_dict = {}\n",
    "    new_u, new_v = [], []\n",
    "    \n",
    "    for idx, val in enumerate(nodes):\n",
    "        nodes_dict[val] = idx\n",
    "    \n",
    "    print(len(nodes_dict), len(edges))\n",
    "    for edge in edges:\n",
    "        new_u.append(nodes_dict[edge[0]])\n",
    "        new_v.append(nodes_dict[edge[1]])\n",
    "    \n",
    "    u = torch.tensor(new_u)\n",
    "    v = torch.tensor(new_v)\n",
    "    g = dgl.graph((u, v))\n",
    "    G = g.to_networkx()\n",
    "    return g, G\n",
    "    \n",
    "    \n",
    "lg, LG = create_dgl_nx_dual_graph(LnxG)\n",
    "dual_edges_dict = {edge: num for num, edge in enumerate(list(LG.edges()))}\n",
    "dual_nodes_dict = {node: num for num, node in enumerate(sorted(list(LnxG.nodes()),reverse=False))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bde5cb2-c9fe-4130-a2c2-e934d6d7c043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "81\n",
      "[(0, 78), (3, 20), (5, 16), (7, 44), (7, 46), (7, 45), (8, 69), (12, 67), (13, 22), (14, 66)]\n"
     ]
    }
   ],
   "source": [
    "#print(len(dual_nodes_dict))\n",
    "#print(len(dual_edges_dict))\n",
    "print(len(list(LG.nodes)), list(LG.nodes)[:10])\n",
    "print(len(list(LG.edges)))\n",
    "print(list(LG.edges())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20169f77-718c-499f-8092-e8e430156cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 [tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9)]\n",
      "81\n",
      "tensor([ 0, 78, 64,  3,  5, 16, 37,  8,  7,  7]) tensor([ 0, 78, 64,  3,  5, 16, 37,  8,  7,  7])\n"
     ]
    }
   ],
   "source": [
    "print(len(list(lg.nodes())), list(lg.nodes())[:10])\n",
    "print(len(list(lg.edges())[0]))\n",
    "print(list(lg.edges())[0][:10], list(lg.edges())[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81342138-b455-487e-8ca6-3ec570929918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb60953d6e549b39f639d3ae1b5b7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:00<00:00, 888.57it/s]\n",
      "/var/folders/cm/gfrlqbxx32b2v0hgshlc8mk00000gn/T/ipykernel_95899/3184879234.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/distiller/project/pytorch/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  embeddings_dual = torch.tensor(embeddings_dual)\n"
     ]
    }
   ],
   "source": [
    "# create node features to line graph\n",
    "\n",
    "# m = nn.AvgPool1d(2, stride=2)\n",
    "node2vec = Node2Vec(LnxG, dimensions=dimensions, walk_length=walk_length)\n",
    "model_n2v_dual = node2vec.fit(window=window, min_count=min_count)\n",
    "#embeddings_dual = [[alternate_list(model_n2v_dual.wv[x][0],model_n2v_dual.wv[x][1]) for x in list(LnxG.nodes)]]\n",
    "embeddings_dual = [model_n2v_dual.wv[x] for x in list(LG.nodes)]\n",
    "#embeddings_dual = m(torch.tensor(embeddings_dual))[0]\n",
    "#embeddings_dual = (torch.tensor(embeddings_dual))[0]\n",
    "embeddings_dual = torch.tensor(embeddings_dual)\n",
    "lg.ndata['feat'] = embeddings_dual                #f_uv^*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa9ec8df-864f-4c47-ac6d-770965e4a2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(embeddings_dual[:5] - lg.ndata['feat'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a032fd6c-90af-418d-8de6-0fb89b65ad3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=90, num_edges=81,\n",
      "      ndata_schemes={'feat': Scheme(shape=(10,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "train_dual_g = lg #dgl.remove_edges(dual_g, eids[:int(len(dual_eids) * 0.1)]) #subgraph\n",
    "print(train_dual_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b474b427-8b32-439b-9d49-90e96f358a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(train_g.ndata['feat'].shape[1], dimensions)\n",
    "FC_net = FC(dimensions)\n",
    "###############################################################\n",
    "model_dual = GraphSAGE(train_dual_g.ndata['feat'].shape[1], dimensions)\n",
    "FC_net_dual = FC(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "866493b7-286e-46b3-98b8-cc9bb7e4c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_u_star(G, LnxG, pos_score_dual):\n",
    "    node_features = np.zeros((G.number_of_nodes(), dimensions))\n",
    "    counts = np.zeros((G.number_of_nodes(), 1))\n",
    "\n",
    "    for node in list(G.nodes()):\n",
    "        for i, edge in enumerate(list(LnxG.edges())):\n",
    "            if (node in edge[0])or(node in edge[1]):\n",
    "                n1, n2 = dual_nodes_dict[edge[0]], dual_nodes_dict[edge[1]]\n",
    "                #print(edge, n1, n2)\n",
    "                try:\n",
    "                    num_embd_edge_G_star = dual_edges_dict[(n1, n2)]\n",
    "                    node_features[node] += pos_score_dual[num_embd_edge_G_star].detach().numpy()\n",
    "                    counts[node] += 1\n",
    "                    #print(pos_score_dual[num_embd_edge_G_star])\n",
    "                except: print('NUN', edge)\n",
    "        #print(counts)\n",
    "        if counts[node] != 0:\n",
    "            node_features[node]/=counts[node]\n",
    "        \n",
    "    return torch.from_numpy(node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6ce21711-2b5a-45a0-a90f-0532b1e3c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_for_train_SAGE(alpha, beta, z_u, g_u_star, g_uv, z_uv_star):\n",
    "    res1 = alpha*((z_u - g_u_star)**2).mean()\n",
    "    res2 = beta*((g_uv - z_uv_star)**2).mean()\n",
    "    return res1 + res2 \n",
    "    # return alfa*((z_u - g_u_star)**2).mean() + beta*((g_uv - z_uv_star)**2).mean()\n",
    "    #return alfa*F.binary_cross_entropy_with_logits(z_u, g_u_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b6352b08-d618-46f3-8165-01b9873ddd17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "  2%|▏         | 17/1000 [00:00<00:11, 83.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.00018082465955771674, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 54/1000 [00:00<00:10, 89.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 40, loss: 0.00017779051883315492, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 92/1000 [00:01<00:10, 90.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 80, loss: 0.00016884397023442295, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 132/1000 [00:01<00:09, 90.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 120, loss: 0.00016698185843143335, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 172/1000 [00:01<00:09, 91.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 160, loss: 0.0001661436410433561, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 212/1000 [00:02<00:08, 92.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 200, loss: 0.00016530659797536404, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 252/1000 [00:02<00:08, 89.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 240, loss: 0.00016459814056402988, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 290/1000 [00:03<00:07, 91.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 280, loss: 0.00016409728709226658, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 330/1000 [00:03<00:07, 88.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 320, loss: 0.00016384007597528743, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 375/1000 [00:04<00:07, 82.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 360, loss: 0.00016387872700105097, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 412/1000 [00:04<00:06, 85.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 400, loss: 0.00016347860720739, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 451/1000 [00:05<00:06, 90.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 440, loss: 0.00016353191520661946, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 491/1000 [00:05<00:05, 90.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 480, loss: 0.000163239886715778, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 537/1000 [00:06<00:05, 85.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 520, loss: 0.00016326235727851193, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 574/1000 [00:06<00:04, 86.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 560, loss: 0.00016299687180167512, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 612/1000 [00:06<00:04, 90.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 600, loss: 0.00016294320323419936, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 652/1000 [00:07<00:03, 90.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 640, loss: 0.00016283922483608727, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 692/1000 [00:07<00:03, 91.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 680, loss: 0.0001644452939164408, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 732/1000 [00:08<00:02, 91.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 720, loss: 0.00016349094429025455, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 772/1000 [00:08<00:02, 92.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 760, loss: 0.00016295017044000014, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 812/1000 [00:09<00:02, 92.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 800, loss: 0.00016294290629722763, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 852/1000 [00:09<00:01, 92.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 840, loss: 0.00016271266602705577, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 892/1000 [00:09<00:01, 92.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 880, loss: 0.00016272611107129547, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 932/1000 [00:10<00:00, 92.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 920, loss: 0.00016276756671540694, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 972/1000 [00:10<00:00, 92.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 960, loss: 0.00016270205210827261, time_g_u_s: 0 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:11<00:00, 89.40it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), FC_net.parameters()), lr=0.01)\n",
    "optimizer_d = torch.optim.Adam(itertools.chain(model_dual.parameters(), FC_net_dual.parameters()), lr=0.01)\n",
    "\n",
    "all_logits, diff = [], 0\n",
    "alpha, beta = 0.4, 0.9\n",
    "\n",
    "for e in tqdm(range(1000)):\n",
    "    h = model(train_g, embeddings)                              #z_u\n",
    "    h_dual = model_dual(train_dual_g, embeddings_dual)          #z_uv^*\n",
    "    \n",
    "    pos_score = FC_net(train_g, h)                              #g_uv\n",
    "    #neg_score = pred(train_neg_g, h)                           #g_uv -\n",
    "    pos_score_dual = FC_net_dual(train_dual_g, h_dual)          #g_u^*\n",
    "    #neg_score_dual = pred(train_neg_dual_g, h_dual)            #g_u^* -\n",
    "    start = time.time()\n",
    "    g_u_s = g_u_star(G, LnxG, pos_score_dual)\n",
    "    end = time.time()\n",
    "    diff += int(end - start)\n",
    "    loss = compute_loss_for_train_SAGE(alpha, beta, h, g_u_s, pos_score, h_dual)\n",
    "    \n",
    "    # print(h.shape)\n",
    "    # print(h_dual.shape)\n",
    "    # print(pos_score.shape)\n",
    "    # print(pos_score_dual.shape)\n",
    "    # print(g_u_s.shape)\n",
    "    # print(loss, F.mse_loss(h, g_u_s), F.mse_loss(pos_score, h_dual))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    optimizer_d.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer_d.step()\n",
    "\n",
    "    if e % 40 == 0:\n",
    "        print('In epoch {}, loss: {}, time_g_u_s: {} s'.format(e, loss, diff))\n",
    "        diff = 0\n",
    "    \n",
    "# torch.Size([7, 3])\n",
    "# torch.Size([8, 3])\n",
    "# torch.Size([8, 3])\n",
    "# torch.Size([12, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71a51fd-aa69-4c33-bdcf-be7ba22979ad",
   "metadata": {},
   "source": [
    "# LP Task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "313e3995-6245-4dc5-8895-c117bae728b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])    \n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "    #return ((scores - labels)**2).mean() \n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1e87e2d9-ff74-47eb-96e5-e8c0bad94195",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lp = GraphSAGE(train_g.ndata['feat'].shape[1], 20)\n",
    "pred_lp = MLPPredictor(dimensions)\n",
    "#pred_lp = DotPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e7f1d914-2e9f-474c-a812-67785a784425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=100, num_edges=90,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n",
      "Graph(num_nodes=100, num_edges=40,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "print(train_pos_g)\n",
    "print(train_neg_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2d7b9ee6-510d-4247-907f-a86eb0808d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.00016302126525493215\n",
      "In epoch 10, loss: 0.00016302126525493215\n",
      "In epoch 20, loss: 0.00016302126525493215\n",
      "In epoch 30, loss: 0.00016302126525493215\n",
      "In epoch 40, loss: 0.00016302126525493215\n",
      "In epoch 50, loss: 0.00016302126525493215\n",
      "In epoch 60, loss: 0.00016302126525493215\n",
      "In epoch 70, loss: 0.00016302126525493215\n",
      "In epoch 80, loss: 0.00016302126525493215\n",
      "In epoch 90, loss: 0.00016302126525493215\n",
      "In epoch 100, loss: 0.00016302126525493215\n",
      "In epoch 110, loss: 0.00016302126525493215\n",
      "In epoch 120, loss: 0.00016302126525493215\n",
      "In epoch 130, loss: 0.00016302126525493215\n",
      "In epoch 140, loss: 0.00016302126525493215\n",
      "In epoch 150, loss: 0.00016302126525493215\n",
      "In epoch 160, loss: 0.00016302126525493215\n",
      "In epoch 170, loss: 0.00016302126525493215\n",
      "In epoch 180, loss: 0.00016302126525493215\n",
      "In epoch 190, loss: 0.00016302126525493215\n",
      "AUC 0.45\n"
     ]
    }
   ],
   "source": [
    "optimizer_lp = torch.optim.Adam(pred_lp.parameters(), lr=0.01)\n",
    "\n",
    "all_logits = []\n",
    "for e in range(200):\n",
    "    model.eval()\n",
    "    h_after_GCN = model(train_g, embeddings)  #train_g.ndata['feat'])\n",
    "    pos_score = pred_lp(train_pos_g, h_after_GCN)\n",
    "    neg_score = pred_lp(train_neg_g, h_after_GCN)\n",
    "    loss_lp = compute_loss(pos_score, neg_score)\n",
    "    \n",
    "    #print(loss_lp)\n",
    "    \n",
    "    optimizer_lp.zero_grad()\n",
    "    loss_lp.backward(retain_graph=True)\n",
    "    optimizer_lp.step()\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(e, loss))\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "with torch.no_grad():\n",
    "    pos_score = pred_lp(test_pos_g, h)\n",
    "    neg_score = pred_lp(test_neg_g, h)\n",
    "    print('AUC', compute_auc(pos_score, neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f15a8ba9-27e6-4318-8f92-7e7bf1cf5235",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e43c614e-94de-4d1f-973b-15b885aa8ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha, beta = 0.4 , 0.9 -> AUC 0.45\n"
     ]
    }
   ],
   "source": [
    "print('alpha, beta =', alpha, ',',beta, '-> AUC', compute_auc(pos_score, neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58984145-2c6b-4f85-afd6-953039659008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha, beta = 0.5, 1.0 -> AUC 0.55\n",
    "# alpha, beta = 0.25, 1.0 -> AUC 0.525\n",
    "# alpha, beta = 0.1, 1.0 -> AUC 0.5\n",
    "\n",
    "# alpha, beta = 0.9, 0.9 -> AUC 0.48\n",
    "# alpha, beta = 1.0, 0.5 -> AUC 0.48\n",
    "# alpha, beta = 1.0, 0.25 -> AUC 0.45\n",
    "\n",
    "# alpha, beta = 0.5, 0.9 -> AUC 0.54\n",
    "# alpha, beta = 0.5, 0.5 -> AUC 0.59\n",
    "# alpha, beta = 0.1, 0.5 -> AUC 0.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d25159d-49ff-4aee-974d-0c507ab3f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha, beta = 0.5, 1. -> AUC 0.7399"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
