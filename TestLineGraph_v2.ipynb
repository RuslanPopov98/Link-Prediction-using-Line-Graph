{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "f2085da5-e0d3-4179-868b-5c4244457275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "import scipy.sparse as sp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import dgl.function as fn\n",
    "import dgl.nn.pytorch as dglnn\n",
    "import itertools\n",
    "from dgl.nn import GraphConv\n",
    "from dgl.nn import SumPooling\n",
    "from dgl.nn import DenseGraphConv\n",
    "from dgl.nn import SAGEConv\n",
    "import dgl.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "926081bd-ee99-4d16-a192-0b91f9bd8e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "a4df005e-6040-4e6e-8a11-a9dadc7295ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "726610fd-d1a1-4c44-827d-b85ed277a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats*2, h_feats*2)\n",
    "        self.W2 = nn.Linear(h_feats*2, h_feats)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "18b2e5da-9693-4c99-bd90-3fdc660cccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_sample(graph, test_size=0.1):\n",
    "    u, v = graph.edges()\n",
    "    eids = np.random.permutation(np.arange(graph.number_of_edges())) #random index edges\n",
    "    test_size_idx = int(len(eids) * test_size) #size positive sample by index\n",
    "\n",
    "    test_pos_u, test_pos_v = u[eids[:test_size_idx]], v[eids[:test_size_idx]]\n",
    "    train_pos_u, train_pos_v = u[eids[test_size_idx:]], v[eids[test_size_idx:]] \n",
    "    \n",
    "    train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=graph.number_of_nodes())\n",
    "    test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=graph.number_of_nodes())\n",
    "    \n",
    "    return train_pos_g, test_pos_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "ae313913-133f-4bd5-a790-72893ac0fa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# dataset = dgl.data.CoraGraphDataset()\n",
    "# g = dataset[0]\n",
    "# G = g.to_networkx()\n",
    "\n",
    "# edges = [\n",
    "#         ['7', '6'],\n",
    "#         ['6', '5'],\n",
    "#         ['5', '4'],\n",
    "#         ['5', '2'],\n",
    "#         ['4', '3'],\n",
    "#         ['2', '1'],\n",
    "#         ['2', '3'],\n",
    "#         ['3', '1'],\n",
    "#         ]\n",
    "# G = nx.Graph()\n",
    "# G.add_edges_from(edges)\n",
    "# g = dgl.from_networkx(G)\n",
    "\n",
    "u = torch.tensor([6,5,4,4,3,1,1,2])\n",
    "v = torch.tensor([5,4,3,1,2,0,2,0])\n",
    "g = dgl.graph((u, v))\n",
    "G = g.to_networkx()\n",
    "print(len(list(G.nodes())))\n",
    "print(len(list(G.edges())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "d9e222c3-331e-482c-8f55-5537b992e44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "[tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6)]\n"
     ]
    }
   ],
   "source": [
    "print(list(G.nodes()))\n",
    "print(list(g.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "31d220ac-265b-458c-83d2-ae8d0422a7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 2), (2, 0), (3, 2), (4, 3), (4, 1), (5, 4), (6, 5)]\n",
      "[tensor([6, 5, 4, 4, 3, 1, 1, 2]), tensor([5, 4, 3, 1, 2, 0, 2, 0])]\n"
     ]
    }
   ],
   "source": [
    "print(list(G.edges()))\n",
    "print(list(g.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "8114e570-dbcd-483f-b497-6e5cf88db04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alternate_list(a,b):\n",
    "    c = list()\n",
    "    for x in range(len(a)):\n",
    "        c.extend([a[x], b[x]])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "75282fae-dbf9-465b-9663-20b59dd07664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4a784865b143d2a3f15dfd40906277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:00<00:00, 5872.73it/s]\n"
     ]
    }
   ],
   "source": [
    "node2vec = Node2Vec(G, dimensions=3, walk_length=3)#, workers=6)\n",
    "model_n2v = node2vec.fit(window=3, min_count=1)\n",
    "embeddings = np.array([model_n2v.wv[x] for x in list(G.nodes())])\n",
    "embeddings = torch.from_numpy(embeddings)\n",
    "g.ndata['feat'] = embeddings                       # f_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "d5609be2-44fc-46ec-bda8-8c20b2124b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "[tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6)]\n"
     ]
    }
   ],
   "source": [
    "print(list(G.nodes()))\n",
    "print(list(g.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "078ea938-0d43-47c9-a6fe-3f50d8a72fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0178,  0.0078,  0.1701],\n",
       "        [ 0.3004, -0.3102, -0.2373],\n",
       "        [ 0.2153,  0.2991, -0.1672],\n",
       "        [-0.1254,  0.2460, -0.0512],\n",
       "        [-0.1512,  0.2184, -0.1620],\n",
       "        [-0.0604,  0.0958,  0.0330],\n",
       "        [-0.2761, -0.3150,  0.2437]])"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "40662744-05d7-4049-b74d-a872cad39de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0178,  0.0078,  0.1701],\n",
       "        [ 0.3004, -0.3102, -0.2373],\n",
       "        [ 0.2153,  0.2991, -0.1672],\n",
       "        [-0.1254,  0.2460, -0.0512],\n",
       "        [-0.1512,  0.2184, -0.1620],\n",
       "        [-0.0604,  0.0958,  0.0330],\n",
       "        [-0.2761, -0.3150,  0.2437]])"
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.ndata['feat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "c08b353d-e5f4-4371-b8a3-a58354b422ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01777828,  0.00778672,  0.17005034], dtype=float32)"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_n2v.wv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "1d4d5886-f85f-4926-be1c-48c5a15008b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=7, num_edges=8,\n",
      "      ndata_schemes={'feat': Scheme(shape=(3,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "eids = np.random.permutation(np.arange(g.number_of_edges()))\n",
    "train_g = g#dgl.remove_edges(g, eids[:int(len(eids) * 0.1)]) #subgraph\n",
    "print(train_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a895d3e2-bd7e-406e-a819-65641ac3f26f",
   "metadata": {},
   "source": [
    "### line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "9a8098c4-193e-4e47-913d-25d808254d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_G = nx.Graph()\n",
    "temp_G.add_edges_from(list(G.edges()))\n",
    "LnxG = nx.line_graph(temp_G)\n",
    "# #lg = g.line_graph(backtracking=False)\n",
    "# #lg = dgl.from_networkx(G).line_graph(backtracking=False)\n",
    "# lg = dgl.from_networkx(LnxG)\n",
    "# LG = lg.to_networkx()\n",
    "\n",
    "# dual_nodes_dict = {}\n",
    "# for idx, val in enumerate(list(LnxG.nodes())):\n",
    "#     dual_nodes_dict[val] = idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "960e5b33-0d0e-497b-ba52-3fda882b4c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (0, 2), (1, 2), (1, 4), (2, 3), (3, 4), (4, 5), (5, 6)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EdgeView([((5, 6), (4, 5)), ((1, 4), (3, 4)), ((1, 4), (1, 2)), ((1, 4), (0, 1)), ((1, 4), (4, 5)), ((3, 4), (2, 3)), ((3, 4), (4, 5)), ((0, 2), (1, 2)), ((0, 2), (2, 3)), ((0, 2), (0, 1)), ((1, 2), (2, 3)), ((1, 2), (0, 1))])"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sorted(list(LnxG.nodes()),reverse=False))\n",
    "LnxG.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "43154966-2fb3-4e14-9292-3667905d07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dgl_nx_dual_graph(line_nx_graph):\n",
    "    nodes = sorted(list(line_nx_graph.nodes()),reverse=False)\n",
    "    edges = list(line_nx_graph.edges())\n",
    "    nodes_dict = {}\n",
    "    new_u, new_v = [], []\n",
    "    \n",
    "    for idx, val in enumerate(nodes):\n",
    "        nodes_dict[val] = idx\n",
    "    \n",
    "    for edge in edges:\n",
    "        new_u.append(nodes_dict[edge[0]])\n",
    "        new_v.append(nodes_dict[edge[1]])\n",
    "    \n",
    "    u = torch.tensor(new_u)\n",
    "    v = torch.tensor(new_v)\n",
    "    g = dgl.graph((u, v))\n",
    "    G = g.to_networkx()\n",
    "    return g, G\n",
    "    \n",
    "    \n",
    "lg, LG = create_dgl_nx_dual_graph(LnxG)\n",
    "dual_edges_dict = {edge: num for num, edge in enumerate(list(LG.edges()))}\n",
    "dual_nodes_dict = {node: num for num, node in enumerate(sorted(list(LnxG.nodes()),reverse=False))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "4bde5cb2-c9fe-4130-a2c2-e934d6d7c043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1): 0, (0, 2): 1, (1, 2): 2, (1, 4): 3, (2, 3): 4, (3, 4): 5, (4, 5): 6, (5, 6): 7}\n",
      "{(1, 2): 0, (1, 4): 1, (1, 0): 2, (2, 4): 3, (2, 0): 4, (3, 5): 5, (3, 2): 6, (3, 0): 7, (3, 6): 8, (5, 4): 9, (5, 6): 10, (7, 6): 11}\n",
      "8 [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "12\n",
      "[(1, 2), (1, 4), (1, 0), (2, 4), (2, 0), (3, 5), (3, 2), (3, 0), (3, 6), (5, 4), (5, 6), (7, 6)]\n"
     ]
    }
   ],
   "source": [
    "print(dual_nodes_dict)\n",
    "print(dual_edges_dict)\n",
    "print(len(list(LG.nodes)), list(LG.nodes))\n",
    "print(len(list(LG.edges)))\n",
    "print(list(LG.edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "20169f77-718c-499f-8092-e8e430156cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 [tensor(0), tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6), tensor(7)]\n",
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([7, 3, 3, 3, 3, 5, 5, 1, 1, 1, 2, 2]),\n",
       " tensor([6, 5, 2, 0, 6, 4, 6, 2, 4, 0, 4, 0])]"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(list(lg.nodes())), list(lg.nodes()))\n",
    "print(len(list(lg.edges())[0]))\n",
    "list(lg.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "e40a89d8-fde9-4791-b95d-cbf941d02ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3003091 , -0.31009832, -0.23722696], dtype=float32)"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_n2v_dual.wv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "81342138-b455-487e-8ca6-3ec570929918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd065cf5435c4daf92d73ccb08fbacd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:00<00:00, 12706.16it/s]\n"
     ]
    }
   ],
   "source": [
    "m = nn.AvgPool1d(2, stride=2)\n",
    "node2vec = Node2Vec(LnxG, dimensions=3, walk_length=3)\n",
    "model_n2v_dual = node2vec.fit(window=3, min_count=1)\n",
    "#embeddings_dual = [[alternate_list(model_n2v_dual.wv[x][0],model_n2v_dual.wv[x][1]) for x in list(LnxG.nodes)]]\n",
    "embeddings_dual = [model_n2v_dual.wv[x] for x in list(LG.nodes)]\n",
    "#embeddings_dual = m(torch.tensor(embeddings_dual))[0]\n",
    "#embeddings_dual = (torch.tensor(embeddings_dual))[0]\n",
    "embeddings_dual = torch.tensor(embeddings_dual)\n",
    "lg.ndata['feat'] = embeddings_dual                #f_uv^*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "fa9ec8df-864f-4c47-ac6d-770965e4a2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0178,  0.0084,  0.1703],\n",
       "        [ 0.3004, -0.3099, -0.2372],\n",
       "        [ 0.2159,  0.3000, -0.1677],\n",
       "        [-0.1253,  0.2462, -0.0513],\n",
       "        [-0.1512,  0.2187, -0.1620],\n",
       "        [-0.0604,  0.0961,  0.0330],\n",
       "        [-0.2759, -0.3143,  0.2436],\n",
       "        [ 0.1691,  0.2252,  0.0254]])"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.ndata['feat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "0fe1affe-4c0c-4877-a490-ebf16427457e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0178,  0.0084,  0.1703],\n",
       "        [ 0.3004, -0.3099, -0.2372],\n",
       "        [ 0.2159,  0.3000, -0.1677],\n",
       "        [-0.1253,  0.2462, -0.0513],\n",
       "        [-0.1512,  0.2187, -0.1620],\n",
       "        [-0.0604,  0.0961,  0.0330],\n",
       "        [-0.2759, -0.3143,  0.2436],\n",
       "        [ 0.1691,  0.2252,  0.0254]])"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "cfde5c49-1442-467f-9d6a-992fc941fc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "a032fd6c-90af-418d-8de6-0fb89b65ad3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=8, num_edges=12,\n",
      "      ndata_schemes={'feat': Scheme(shape=(3,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "dual_eids = np.random.permutation(np.arange(dual_g.number_of_edges()))\n",
    "train_dual_g = lg#dgl.remove_edges(dual_g, eids[:int(len(dual_eids) * 0.1)]) #subgraph\n",
    "print(train_dual_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "331b7151-e521-4c03-8378-3ccb6a12e2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(train_dual_g.nodes))\n",
    "# list(train_dual_g.edges)\n",
    "#list(train_dual_g.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "b474b427-8b32-439b-9d49-90e96f358a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(train_g.ndata['feat'].shape[1], 3)\n",
    "#pred = MLPPredictor(20)\n",
    "FC_net = FC(3)\n",
    "###############################################################\n",
    "model_dual = GraphSAGE(train_dual_g.ndata['feat'].shape[1], 3)\n",
    "#pred_dual = MLPPredictor(20)\n",
    "FC_net_dual = FC(3)\n",
    "#model = SAGE(train_g.ndata['feat'].shape[1], 20, 4, F.relu, 0.25)\n",
    "#pred = DotPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "eba31753-bfb7-47a5-8de2-cb4048f024e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_g, test_pos_g = positive_sample(g)\n",
    "#train_neg_g, test_neg_g = negative_sample(g, 'dgl_example')\n",
    "###########################################################\n",
    "train_pos_dual_g, test_pos_dual_g = positive_sample(dual_g)\n",
    "#train_neg_dual_g, test_neg_dual_g = negative_sample(dual_g, 'dgl_example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "4e0e5629-90ea-4c79-8292-9ed4a2bfce5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 1): 0, (0, 2): 1, (1, 2): 2, (1, 4): 3, (2, 3): 4, (3, 4): 5, (4, 5): 6, (5, 6): 7}\n",
      "{(1, 2): 0, (1, 4): 1, (1, 0): 2, (2, 4): 3, (2, 0): 4, (3, 5): 5, (3, 2): 6, (3, 0): 7, (3, 6): 8, (5, 4): 9, (5, 6): 10, (7, 6): 11}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((5, 6), (4, 5)),\n",
       " ((1, 4), (3, 4)),\n",
       " ((1, 4), (1, 2)),\n",
       " ((1, 4), (0, 1)),\n",
       " ((1, 4), (4, 5)),\n",
       " ((3, 4), (2, 3)),\n",
       " ((3, 4), (4, 5)),\n",
       " ((0, 2), (1, 2)),\n",
       " ((0, 2), (2, 3)),\n",
       " ((0, 2), (0, 1)),\n",
       " ((1, 2), (2, 3)),\n",
       " ((1, 2), (0, 1))]"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dual_nodes_dict)\n",
    "print(dual_edges_dict)\n",
    "list(LnxG.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "866493b7-286e-46b3-98b8-cc9bb7e4c42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_u_star(G, LnxG, pos_score_dual):\n",
    "    node_features = np.zeros((G.number_of_nodes(), 3))\n",
    "    counts = np.zeros((G.number_of_nodes(), 1))\n",
    "\n",
    "    for node in list(G.nodes()):\n",
    "        for i, edge in enumerate(list(LnxG.edges())):\n",
    "            if (node in edge[0])or(node in edge[1]):\n",
    "                n1, n2 = dual_nodes_dict[edge[0]], dual_nodes_dict[edge[1]]\n",
    "                #print(edge, n1, n2)\n",
    "                try:\n",
    "                    num_embd_edge_G_star = dual_edges_dict[(n1, n2)]\n",
    "                    node_features[node] += pos_score_dual[num_embd_edge_G_star].detach().numpy()\n",
    "                    counts[node] += 1\n",
    "                    #print(pos_score_dual[num_embd_edge_G_star])\n",
    "                except: print('NUN', edge)\n",
    "        #print(counts)\n",
    "        node_features[node]/=counts[node]\n",
    "        \n",
    "    return torch.from_numpy(node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "6ce21711-2b5a-45a0-a90f-0532b1e3c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_1(z_u, g_u_star, g_uv, z_uv_star):\n",
    "    alfa, beta = 0.5, 1.\n",
    "    return alfa*((z_u - g_u_star)**2).mean()+ beta*((g_uv - z_uv_star)**2).mean()\n",
    "    #return alfa*F.binary_cross_entropy_with_logits(z_u, g_u_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "b6352b08-d618-46f3-8165-01b9873ddd17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.01277326616859916\n",
      "In epoch 5, loss: 0.01681630470207198\n",
      "In epoch 10, loss: 0.010242130856540651\n",
      "In epoch 15, loss: 0.008550427610994438\n",
      "In epoch 20, loss: 0.007389001131371489\n",
      "In epoch 25, loss: 0.00577109339677789\n",
      "In epoch 30, loss: 0.004620463219397593\n",
      "In epoch 35, loss: 0.003951856506024801\n",
      "In epoch 40, loss: 0.0033986713514497155\n",
      "In epoch 45, loss: 0.0029529082138656086\n",
      "In epoch 50, loss: 0.002652940439605037\n",
      "In epoch 55, loss: 0.002427889413865857\n",
      "In epoch 60, loss: 0.0022473620735191245\n",
      "In epoch 65, loss: 0.0020936153244302718\n",
      "In epoch 70, loss: 0.001961116767713322\n",
      "In epoch 75, loss: 0.0018484154059261464\n",
      "In epoch 80, loss: 0.0017473560971392364\n",
      "In epoch 85, loss: 0.0016541980818947403\n",
      "In epoch 90, loss: 0.0015641118044984817\n",
      "In epoch 95, loss: 0.0014805688572663653\n",
      "In epoch 100, loss: 0.0014033087895842958\n",
      "In epoch 105, loss: 0.0013311204580587922\n",
      "In epoch 110, loss: 0.0012619693389666693\n",
      "In epoch 115, loss: 0.0011965469031552667\n",
      "In epoch 120, loss: 0.001135110953647053\n",
      "In epoch 125, loss: 0.0010772693956424139\n",
      "In epoch 130, loss: 0.0010227427782020665\n",
      "In epoch 135, loss: 0.0009714084931692759\n",
      "In epoch 140, loss: 0.0009229447357401977\n",
      "In epoch 145, loss: 0.0008772186345719713\n",
      "In epoch 150, loss: 0.0008340181014219036\n",
      "In epoch 155, loss: 0.000793191679802315\n",
      "In epoch 160, loss: 0.0007546050517773769\n",
      "In epoch 165, loss: 0.0007181064397895914\n",
      "In epoch 170, loss: 0.0006835857428365176\n",
      "In epoch 175, loss: 0.0006509255998476685\n",
      "In epoch 180, loss: 0.0006200199720790924\n",
      "In epoch 185, loss: 0.0005907714603840183\n",
      "In epoch 190, loss: 0.0005630854633483332\n",
      "In epoch 195, loss: 0.0005368770601989115\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), FC_net.parameters()), lr=0.01)\n",
    "optimizer_d = torch.optim.Adam(itertools.chain(model_dual.parameters(), FC_net_dual.parameters()), lr=0.01)\n",
    "\n",
    "all_logits = []\n",
    "for e in range(200):\n",
    "    h = model(train_g, embeddings)                              #z_u\n",
    "    h_dual = model_dual(train_dual_g, embeddings_dual)          #z_uv^*\n",
    "    \n",
    "    pos_score = FC_net(train_g, h)                              #g_uv\n",
    "    #neg_score = pred(train_neg_g, h)                           #g_uv -\n",
    "    pos_score_dual = FC_net_dual(train_dual_g, h_dual)          #g_u^*\n",
    "    #neg_score_dual = pred(train_neg_dual_g, h_dual)            #g_u^* -\n",
    "    g_u_s = g_u_star(G, LnxG, pos_score_dual)\n",
    "    #loss = compute_loss(pos_score, neg_score) \n",
    "    loss = compute_loss_1(h, g_u_s, pos_score, h_dual)\n",
    "    \n",
    "    # print(h.shape)\n",
    "    # print(h_dual.shape)\n",
    "    # print(pos_score.shape)\n",
    "    # print(pos_score_dual.shape)\n",
    "    # print(g_u_s.shape)\n",
    "    # print(loss, F.mse_loss(h, g_u_s), F.mse_loss(pos_score, h_dual))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    optimizer_d.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer_d.step()\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(e, loss))\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#with torch.no_grad():\n",
    "    #pos_score = pred(test_pos_g, h)\n",
    "    #neg_score = pred(test_neg_g, h)\n",
    "    #print('AUC', compute_auc(pos_score, neg_score))\n",
    "    \n",
    "# torch.Size([7, 3])\n",
    "# torch.Size([8, 3])\n",
    "# torch.Size([8, 3])\n",
    "# torch.Size([12, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f15a8ba9-27e6-4318-8f92-7e7bf1cf5235",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "d92b4a8c-1ab4-4ef2-ba4b-4177f77b8c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1895,  0.2487, -0.6351],\n",
       "        [-0.4397, -0.1313, -0.2609],\n",
       "        [-0.0283,  0.1321, -0.2620],\n",
       "        [-0.1150, -0.0431, -0.2199],\n",
       "        [ 0.0915,  0.4219, -0.5364],\n",
       "        [-0.4543,  0.4381, -1.2338],\n",
       "        [-0.2357, -0.0734, -0.5800]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "02baa594-bf77-41d2-be70-023d9bd5e5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [ 4.4662e-01,  2.7341e-01,  1.8396e-02],\n",
       "        [ 1.6291e+00,  4.9753e-01, -6.8852e-02],\n",
       "        [ 1.1003e+00,  2.7436e-04,  6.5087e-02],\n",
       "        [-8.0129e-02, -4.1977e-01, -4.7048e-01],\n",
       "        [-4.8734e-02, -3.3388e-01, -2.9173e-01],\n",
       "        [ 9.1707e-02, -5.8726e-01, -5.1457e-01],\n",
       "        [-3.4101e-01,  6.5786e-01,  3.7019e-01]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "58984145-2c6b-4f85-afd6-953039659008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0212,  0.0677, -0.1386],\n",
       "        [-0.0866,  0.1284, -0.1042],\n",
       "        [ 0.1637,  0.1365, -0.0231],\n",
       "        [ 0.1685,  0.1659,  0.0049],\n",
       "        [ 0.0629,  0.0803, -0.0989],\n",
       "        [-0.0652,  0.0914, -0.1452],\n",
       "        [-0.0118,  0.0758, -0.1214],\n",
       "        [ 0.0554,  0.0850, -0.0968]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "2d25159d-49ff-4aee-974d-0c507ab3f51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0179,  0.0079,  0.1701],\n",
       "        [ 0.3003, -0.3101, -0.2372],\n",
       "        [ 0.2153,  0.2991, -0.1672],\n",
       "        [-0.1254,  0.2460, -0.0511],\n",
       "        [-0.1512,  0.2185, -0.1620],\n",
       "        [-0.0605,  0.0959,  0.0331],\n",
       "        [-0.2762, -0.3150,  0.2437],\n",
       "        [ 0.1690,  0.2253,  0.0254]])"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026cd357-948a-438d-bcba-fbdc95ec8e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89460b9f-269a-4f48-8903-d0486feb6174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d334a-2342-485e-930d-14a4f318e0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16c9f14-6f07-4932-871e-4968d8138b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b3cd6-6be8-488c-b2b8-bebd9ec46c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de018d8-c420-44ac-bb4b-ce12d5f53854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea492ff-9893-47de-a627-4a4e87a7fe04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079353bc-d2d6-43ea-91b0-e030ee550d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c156b4d-1dec-4082-9d7c-4c27f23123d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf41c2d-36c2-4676-b52a-4ca6c83fa53b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a30c445-01df-4222-9b70-256894eefe9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc53f0c-7ea7-4451-9bc0-1b2f91529229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e92a085-a54a-47d3-add1-434b9ce3d7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d377ff42-5a5e-419d-96f9-5c40e61e5064",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.706829845905304\n",
      "In epoch 5, loss: 0.6571868062019348\n",
      "In epoch 10, loss: 0.6407327055931091\n",
      "In epoch 15, loss: 0.6243399381637573\n",
      "In epoch 20, loss: 0.6006797552108765\n",
      "In epoch 25, loss: 0.5711714625358582\n",
      "In epoch 30, loss: 0.546612560749054\n",
      "In epoch 35, loss: 0.5299765467643738\n",
      "In epoch 40, loss: 0.5167433023452759\n",
      "In epoch 45, loss: 0.5066409111022949\n",
      "In epoch 50, loss: 0.4984222650527954\n",
      "In epoch 55, loss: 0.49076011776924133\n",
      "In epoch 60, loss: 0.48473072052001953\n",
      "In epoch 65, loss: 0.48049843311309814\n",
      "In epoch 70, loss: 0.4720494747161865\n",
      "In epoch 75, loss: 0.4649830758571625\n",
      "In epoch 80, loss: 0.4580879807472229\n",
      "In epoch 85, loss: 0.44973331689834595\n",
      "In epoch 90, loss: 0.44106853008270264\n",
      "In epoch 95, loss: 0.4309082329273224\n",
      "AUC 0.8564272029271526\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
    "\n",
    "all_logits = []\n",
    "for e in range(100):\n",
    "    h = model(train_dual_g, embeddings)  #train_g.ndata['feat'])\n",
    "    pos_score = pred(train_pos_g, h)\n",
    "    neg_score = pred(train_neg_g, h)\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(e, loss))\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_g, h)\n",
    "    neg_score = pred(test_neg_g, h)\n",
    "    print('AUC', compute_auc(pos_score, neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c06b19-baf5-4903-a245-180dde215e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d07293-b853-49a1-998f-80eb0f184971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0e1006-c289-4bcf-a772-d498eb83f832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e239f5d-5220-4fbd-b6d7-8ec99cb8fc62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14642290-8d77-4089-8bf1-f5a104beca0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39529b68-7d29-4e29-bc44-ad44f47d2c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08125c99-3a78-427e-958c-868901d2f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g = dgl.remove_edges(g, eids[:1000], ) #subgraph\n",
    "train_g = dgl.remove_nodes(train_g, range(2000))\n",
    "print(train_g)\n",
    "\n",
    "label2 = train_g.ndata['label']\n",
    "nx_G2 = train_g.to_networkx()\n",
    "\n",
    "#visualize(label2, nx_G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af4262f-29ea-4d20-a48b-2a07c00c18f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53eb5d34-4659-4d70-a55f-ff979fe324e9",
   "metadata": {},
   "source": [
    "# TRASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d031c61-b7cc-40bc-bcfa-ec39c1e47857",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data_dir = os.path.expanduser(\"~/data/cora\")\n",
    "\n",
    "data_dir\n",
    "#edgelist = pd.read_csv(os.path.join(data_dir, \"cora.cites\"), sep='\\t', header=None, names=[\"target\", \"source\"])\n",
    "\n",
    "edgelist = pd.read_csv(f\"./data/cora/cora.cites\", sep='\\t', header=None, names=[\"target\", \"source\"])\n",
    "edgelist[\"label\"] = \"cites\"\n",
    "\n",
    "edgelist.sample(frac=1).head(5)\n",
    "\n",
    "Gnx = nx.from_pandas_edgelist(edgelist, edge_attr=\"label\")\n",
    "#nx.set_node_attributes(Gnx, \"paper\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "9a41ff3b-9bb0-4ad8-8f09-8ee1f138c6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6}\n",
      "0 (5, 6)\n",
      "5 6\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Concatenation operation is not implemented for NumPy arrays, use np.concatenate() instead. Please do not rely on this error; it may not be given on all Python implementations.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cm/gfrlqbxx32b2v0hgshlc8mk00000gn/T/ipykernel_77004/3758675949.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mnode_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0medge_embs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mnode_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0medge_embs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Concatenation operation is not implemented for NumPy arrays, use np.concatenate() instead. Please do not rely on this error; it may not be given on all Python implementations."
     ]
    }
   ],
   "source": [
    "nodelist = sorted(G.nodes())\n",
    "adj_mat = sp.csr_matrix(nx.to_numpy_matrix(G, nodelist))\n",
    "args_d = LnxG.number_of_nodes()\n",
    "edgelist = list(LnxG.nodes())\n",
    "\n",
    "edge_embs = h_dual\n",
    "enum = {node: num for num, node in enumerate(list(G.nodes()))}\n",
    "print(enum)\n",
    "num_nodes = adj_mat.shape[0]\n",
    "node_features = np.zeros((num_nodes, args_d))\n",
    "counts = np.ones(num_nodes)\n",
    "for i, edge in enumerate(edgelist):\n",
    "    # средние по эмбеддингам рёбер, связанных с данной вершиной\n",
    "    print(i, edge)\n",
    "    u = enum[edge[0]]; v = enum[edge[1]]\n",
    "    print(u, v)\n",
    "    node_features[u, :] += edge_embs[i, :]\n",
    "    node_features[v, :] -= edge_embs[i, :]\n",
    "    counts[u] += 1; counts[v] += 1\n",
    "node_features /= counts[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58c54a-6dab-40c1-be25-8d6057259517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1879dc13-1ce3-4afe-8d3e-91d805d0a0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca94eef-060f-4ac6-a653-77ffe413ac83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
